env.name=ide
cluster.name=${component.name}"-"${env.name}
instance.fqn=${cluster.name}
log.path.current=/Users/Sumit/Documents/logs/${instance.fqn}
log.path.archive=/Users/Sumit/Documents/logs/${instance.fqn}/archive
log.level=DEBUG
sysout.detach=false
syserr.detach=false
daemon.pidfile=${log.path.current}/${instance.fqn}.pid
port=9999
host=127.0.0.1
server.root =
{
  system{
    conf{
      spark {
        master="yarn"
        deploy-mode="cluster"
        app.name=${instance.fqn}
        spark.executor.memory="5g"
        spark.logConf="true"
        spark.serializer=org.apache.spark.serializer.KryoSerializer
        log4j.rootCategory="WARN, console"
      }
      akka{
        actorSystem="pipelineSystem"
        actors{
          listener="ramanujan_pipeline_listener"
          master="ramanujan_pipeline_master"
          service="ramanujan_service_actor"
        }
      }
    }
  }
  sinks{
    kafka{
      brokers="kafka01.production.askmebazaar.com:9092,kafka02.production.askmebazaar.com:9092,kafka03.production.askmebazaar.com:9092"
      bootstrap.servers="kafka01.production.askmebazaar.com:9092,kafka02.production.askmebazaar.com:9092,kafka03.production.askmebazaar.com:9092"
      metadata.brokers.list="kafka01.production.askmebazaar.com:2181,kafka02.production.askmebazaar.com:2181,kafka03.production.askmebazaar.com:2181"
      group.id="ramanujan"
      producer.type="async"
      key.serializer="org.apache.kafka.common.serialization.StringSerializer"
      value.serializer="org.apache.kafka.common.serialization.StringSerializer"
      auto.create.topics.enable="true"
    }
    hdfs{
      prefixPath="hdfs://"
      tsPartitionEnd=10
      url=localhost
      port=9000
    }
  }
  db{
    conn{
      jdbc=jdbc
    }
    type{
        mysql=mysql
        postgres=postgresql
        sqlserver=sqlserver
    }
    internal{
      driver="com.mysql.jdbc.Driver"
      url=localhost
      user=root
      port=3306
      password=1
      dbname=Ramanujan
      tables{
        requests{
          name=Requests
          cols{
            status=status
            request=request
            processDate=processDate
            host=host
            dbname=dbname
            dbtable=dbtable
          }
          defs{
            defaultStatusVal="0"
          }
        }
        bookmarks{
          name=BookMarks
          cols{
            dbtablekey=primarykey
            id=id
            bookmarkId=bookmark
          }
          defs{
            defaultBookMarkValue="0000"
          }
        }
        statustmp{
          name=Status_tmp
        }
        status{
          name=Status
          cols{
            dbname=dbname
            dbtable=tablename
            primarykey=primarykey
            sourceId=sourceid
            kafkaTargetId=kafkaTargetid
            hdfsTargetId=hdfsTargetid
            qualifiedName=qualifiedName
          }
          defs{
            defaultTargetId="0000"
          }
        }
      }
    }
  }
  type= com.askme.ramanujan.server.RootServer
  port=9999
  host=127.0.0.1
  timeout=120
  actorSystem {
    name=${cluster.name}"-akka"
    akka {
      loggers = ["akka.event.slf4j.Slf4jLogger"]
      loglevel = INFO
    }
    actors {
      listener="ramanujan_pipeline_listener"
      master="ramanujan_pipeline_master"
      service="ramanujan_service_actor"
    }
    spray {
      can.server {
        server-header = ${component.name}
        remote-address-header=on
        request-timeout=120 s
        idle-timeout=600 s
        pipelining-limit = 5
        stats-support = off
        raw-request-uri-header = on
        parsing {
          max-uri-length = 10k
        }
      }
      routing {
        relaxed-header-parsing = on
      }
    }
  }
  spark {
    master="local[4]"
    app.name=${instance.fqn}
    spark.executor.memory="5g"
    spark.logConf="true"
    es.nodes = "mandelbrot01.staging.askmebazaar.com,mandelbrot02.staging.askmebazaar.com,mandelbrot03.staging.askmebazaar.com,mandelbrot04.staging.askmebazaar.com"
    es.port = 9200
    spark.serializer=org.apache.spark.serializer.KryoSerializer
    sun.io.serialization.extendedDebugInfo=true
  }
  handler {
    appname=Ramanujan
    baseurl=/ramanujan
    report=/report
    request=/request
    index.html=web/static/index.html
    timeout {
      scalar=120
      unit=seconds
    }
    name=${instance.fqn}"-http"
    timeoutms=120000
    stream {
      order-pipeline {
        source {
          topic = "orderservice_prod"
          brokers = "kafka01.production.askmebazaar.com:9092,kafka02.production.askmebazaar.com:9092,kafka03.production.askmebazaar.com:9092"
          #brokers = "dc1.staging.askme.com:9092,dc2.staging.askme.com:9092,dc3.staging.askme.com:9092,dc4.staging.askme.com:9092,dc5.staging.askme.com:9092"
        }
      }
    }
  }
}